# 回帰問題：演習課題

**注意：必要に応じて，再利用しやすいように課題ごとにコード名を変更して保存しておくようにすること．**

***
#### 課題 2.1
1. データ [`boston.csv`](./boston.csv) を確認する．また [データの設置されていたWebサイト（外部リンク）](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html) の説明を眺める．
1. コード [`regression.py`](./regression.py) を実行して結果を確認する．データ [`boston.csv`](./boston.csv) を同じフォルダに設置しておくこと．
    > ヒント：データの設置方法については[ColaboratoryにGoogle Driveをマウントする方法](https://github.com/YosukeSugiura/datamining-excercise/blob/master/1_python_basics/EXCERCISE.md#colaboratory%E3%81%A7google-drive%E3%82%92%E3%83%9E%E3%82%A6%E3%83%B3%E3%83%88%E3%81%99%E3%82%8B%E3%81%AB%E3%81%AF)を確認すること．
3. コード [`regression.py`](./regression.py) の意味を読み取る．特徴量として1つしか使っていないことに注意．他の特徴量を使ってプロットして，特徴量から予想される住宅価格の変化と一致するかどうかを確認する．
    > ヒント：`np.loadtxt`の`usecols`はcsvファイルから取り出す列の番号を指定するもの．
4. コードの中の

    ```python
    inputs = inputs[:,np.newaxis]
    ```

    の意味を考える．この前後に `print` を使って `inputs` を出力して見ると違いがわかるはず．また，この部分をコメントアウトして，エラーメッセージを見てみるのもいいかもしれない．

1. コードを別名で保存しておき，プロットする部分を削除する．特徴量をすべて読み込んだり，もしくはいくつかだけ読み込んだりして，係数を調べる．
    > ヒント：`np.loadtxt`の`usecols` を消すと，csvファイルのすべての列を読み込む．
1. scikit-learn (sklearn) の英語のマニュアルを調べるなどして，*R*<sup>2</sup> スコア (score) を出力する．
1. 重回帰分析，標準化，標準偏回帰係数などについて調べ，sklearnのLinearRegressionで標準化をして係数を出力する．（`fit_intercept`というパラメータに注意すること．また標準化については`StandardScaler`について調べてみると良い）
1. （発展）ある一つの特徴量を横軸に，住宅価格を縦軸にプロットする．そのときに，横軸と縦軸のラベルをつける．
1. （発展）モデルから予想した住宅価格と実際の住宅価格との残差を，各データに対してプロットする（横軸がデータ番号，縦軸が残差）．
1. （発展）[`boston.csv`](./boston.csv) を訓練データとテストデータにわける（手動でも，scikit-learnの機能を使ってもいい）．訓練データでフィッティングして，テストデータに対するスコアを出力する．
1. （発展）交差検証法 (Cross Validation) について調べる．実際に交差検証法を使って係数を求めてみる．
1. （発展）住宅価格のデータにおかしな点がないかどうか，プロットしながらを注意深く調べる．その結果を踏まえて，データの前処理を考える．
    > ヒント：データの中には値が適切でないものが存在することもある．予想した住宅価格と実際の住宅価格の残差のプロットも見てみること．
1. （発展）線形回帰の数学について調べる．データ行列を使った求め方があるはずなので，最小二乗法とあわせて理解しておく．
1. （発展）scikit-learn を使わず，numpyの行列演算の機能を使って線形回帰をおこなうコードを書いてみる．


***
#### 課題 2.2
1. リッジ回帰とLASSOを使う方法をwebで調べる．
1. コード [`regression.py`](./regression.py) をもとにして作成した，すべての特徴量を使って回帰をするプログラムにおいて，リッジ回帰とLASSOを使って解析をおこなう．その結果について考察する．
1. 用いる特徴量を変えたりなどして，データ解析の結果から何を言えるか，考察してみる．
1. （発展）コード [`check_regularization.py`](./check_regularization.py) を実行して結果を確認する．データ [`out.csv`](./out.csv) を同じフォルダに設置しておくこと．
1. （発展）8次までの多項式でのフィッティングをおこなうようにコードを改造する．  

    > ヒント：リスト内包表記を使うと比較的簡単．素朴には，以下のようにして1次元配列から，8乗までの入力データを作成できる．

    ```python
    inputs = np.array([[x,x**2,x**3,x**4,x**5,x**6,x**7,x**8] for x in inputs])
    ```

1. （発展）リッジ回帰を使って，8次までの多項式でのフィッティングに対して正則化をする．
1. （発展）線形回帰のコードを自分で組む際，データ行列を使った逆行列の計算において少しだけ計算式を修正することがリッジ回帰に関わってくる．この数理について調べ，コードを自分で書いてみる．
1. （発展）最小二乗法を確率的に解釈すると，ベイズ推定の枠組みにおいてガウス分布を事前分布として用いた場合にリッジ回帰が対応していることがわかる．この数理について調べ，納得し，説明してみる．可能ならばラプラス分布を事前分布として用いた場合がLASSOに対応することも調べ，納得し，説明してみる．

***
[>> 回帰問題のトップページに戻る](./README.md)
***
<img src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png"> &nbsp; Jun Ohkubo
